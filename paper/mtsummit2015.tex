\documentclass[]{article}
\usepackage[letterpaper]{geometry}
\usepackage{mtsummit2015}
\usepackage{times}
%\usepackage{url}
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{natbib}
\usepackage{layout}
\usepackage{multirow}
\usepackage[dvipsnames]{xcolor}  % Coloured text etc.
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\usepackage{listings}
\usepackage{color}
\usepackage{caption}

\newcommand{\confname}{AMTA 2018}
\newcommand{\website}{\protect\url{https://sites.google.com/view/loresmt/}}
\newcommand{\contactname}{research track co-chair Yaser Al-Onaizan}
\newcommand{\contactemail}{chaohong.liu@adaptcentre.ie}
\newcommand{\conffilename}{mtsummit2015}
\newcommand{\downloadsite}{\protect\url{http://www.conference.amtaweb.org/}}
\newcommand{\paperlength}{$8$ (eight)}
\newcommand{\shortpaperlength}{$4$ (four)}

%% do not add any other page- or text-size instruction here

\parskip=0.00in

\begin{document}

% \mtsummitHeader{x}{x}{xxx-xxx}{2015}{45-character paper description goes here}{Author(s) initials and last name go here}
\title{\bf (Un)Supervised Machine Translation \\
  for the \confname~Conference}
\author{\name{\bf Ilya Gusev} \hfill  \addr{ilya.gusev@phystech.edu}\\
        \addr{MPTI, Dolgoprudny, Moscow Region, 141701, Russian Federation}
\AND
        \name{\bf Artem Oboturov} \hfill \addr{oboturov@gmail.com}
}

\maketitle
\pagestyle{empty}

\begin{abstract}
  A comparision of supervised and unsupervised NMT models was done for the corpora provided by the DeepHack.Babel competition.
  \todo[inline]{Write an abstract}
\end{abstract}

\section{Introduction}

\todo[inline]{Write problem statement}

Given the problem at hand one could devise a number of baseline approaches and then compare them to the unsupervised model described above.
Section~\ref{sec:baselines} outlines the baselines which were used to benchmark the UNMT in the oblivious setup.
In Section~\ref{sec:unmt} we perform experiments with the UNMT model for the oblivious setup.
Finally, in Section~\ref{sec:nonoblivious} we are investigating whether prior knowledge of a language pair gives an advantage for the UNMT approach.

\section{Baselines}
\label{sect:baselines}

A supervised NMT model was chosen for the baseline.
The model was implemented in OpenNMT~\citep{opennmt} and had the following Encoder-Decoder architecture:
\begin{itemize}
\item encoder is a continuous embedding from the source language to a $300$ dimensional space;
\item followed by a $3$-layers LSTM with a dropout;
\item the decoder has a stacked LSTM with a dropout, a global attention \citep{bahdanau2014neural} and a continuous embedding from a $300$ dimensional space,
\end{itemize}
full description is given in an Appendix~\ref{appendix:supervised}.

All those models were trained only on a {\tt 50K} parallel corpus with a {\tt 5\%} validation set.
Training time on a NVIDIA Titan XP GPU was usually measured in tens of minutes.
The results are provided in the Table~\ref{table:baselines}.
Another baseline which is reported here is a input to output copy which is reported as the {\tt no-Epochs} baseline.
Embeddings were trained with Fasttext~\citep{bojanowski2016enriching}.

\begin{table}
\begin{center}
\begin{tabular}{ l c c c }
Pair & Epochs & Oblivious Score & Conscious Score \\
\hline
\multirow{5}{4em}{En-Ru} & - & 0.02123 & - \\
& 1 & 0.10783 & \\
& 5 & 0.25747 & \\
& 10 & 0.28915 & \\
& Best & -  & 0.298 \\
\hline
\multirow{5}{4em}{Lv-En} & - & 0.02075 & - \\
& 1 & 0.01142 & \\
& 5 & 0.04766 & \\
& 10 & 0.05756 & \\
& Best & - & 0.229 \\
\hline
\multirow{5}{4em}{En-Ko} & - & 0.02759 & - \\
& 1 & 0.11179 & \\
& 5 & 0.22945 & \\
& 10 & 0.25418 & \\
& Best & - & 0.2795
\end{tabular}
\end{center}
\caption{Supervised NMT baselines, measured in BLEU scores.}
\caption*{\small
The best {\tt Lv-En} and  {\tt En-Ru} are reported on newstest2017 corpora in \cite{bojar2017findings}.
% Lv-En \url{http://matrix.statmt.org/matrix/output/1872?score_id=22981}
%\url{http://matrix.statmt.org/matrix/output/1875?score_id=21229}
{\tt En-Ko} is reported after \cite{junczys2016coppa} which uses COPPA corpus.
}
\label{table:baselines}
\end{table}

One could notice, that on the {\tt Lv-En} langauge pair, model performance was mediocre.
It could be explained by the fact that {\tt En-Ru} and {\tt En-Ko} were topic-resticted corpora - both were descriptions of hotels only, while the {\tt Lv-En} corpora was extracted from a news feed which had no topics constraints.

\section{Unsupervised Neural Machine Translation}
\label{sect:unmt}

\section{Prior Language Pair Information}
\label{sect:nonoblivious}

Competition was structured in a way to prevent participants from knowing what language pairs were being tested.
The only information available to participants was the BLEU score and the failure or success status for the submission.
One could devise at least two attacks to identify the language pair and then using this prior knowledge to consturct a better translation algorithm.

First we explore the nature of those attacks and then measure what might be an impact of such knowledge.

\subsection{Side-Channel Attacks against the Language Pair}
\label{sect:attack}

We describe two ways how language pair identification attack could be executed.

\subsubsection{Using Execution Time}

There's a way to identify the language pair in one submission by using the side-channel attack technique.
In this particular case, the side-channel would be the execution time of the translation algorithm.
Whereby a language identification routine is ran on each of the non-parallel corpora and both languages of the pair are detected.
Given that the routine could identify $N$ languages, all the pairs could be enumerated to define a mapping to natural numbers in rage $1\dots N*(N-1)$.
Provided that a specific constant delay is used, one could divide the total execution time by the delay duration to obtain the index of pair in the mapping.

\subsubsection{Using Failure Status}

The second way is a slower combinatorial way where a failure status is used as an indicator of the language belonging to a subset of languages being tested.
A set of all languages identifiable by the routine could be searched in log-time in a breadth search fashion descending only into subsets where we have established inclusion relationship.

\subsection{Would Prior Knowledge Matter?}
\label{sect:prior}

In the Table~\ref{table:baselines} we also report best BLEU scores available in conference submissions for each of the pairs trained on common corpora.

We could see that a margin of improvement is just a couple of BLEU points for {\tt En-Ru} and {\tt En-Ko} pairs.
One the other hand, {\tt Lv-En} has very poor result and we would expect that both unsupervised learning and prior knowledge would improve this score.
It would make sense to only investigate the {\tt Lv-En} further.

\section{Conclusion}

\small

\bibliographystyle{apalike}
\bibliography{mtsummit2015}

\begin{appendices}
\section{Supervised NMT Model}
\label{appendix:supervised}
\lstinputlisting{supervised-model.txt}
\end{appendices}

\end{document}
