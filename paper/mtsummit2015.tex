\documentclass[]{article}
\usepackage[letterpaper]{geometry}
\usepackage{mtsummit2015}
\usepackage{times}
%\usepackage{url}
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{natbib}
\usepackage{layout}
\usepackage{multirow}
\usepackage[dvipsnames]{xcolor}  % Coloured text etc.
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\usepackage{listings}
\usepackage{color}
\usepackage{caption}

\newcommand{\confname}{AMTA 2018}
\newcommand{\website}{\protect\url{https://sites.google.com/view/loresmt/}}
\newcommand{\contactname}{research track co-chair Yaser Al-Onaizan}
\newcommand{\contactemail}{chaohong.liu@adaptcentre.ie}
\newcommand{\conffilename}{mtsummit2015}
\newcommand{\downloadsite}{\protect\url{http://www.conference.amtaweb.org/}}
\newcommand{\paperlength}{$8$ (eight)}
\newcommand{\shortpaperlength}{$4$ (four)}

%% do not add any other page- or text-size instruction here

\parskip=0.00in

\begin{document}

% \mtsummitHeader{x}{x}{xxx-xxx}{2015}{45-character paper description goes here}{Author(s) initials and last name go here}
\title{\bf (Un)Supervised Machine Translation \\
  for the \confname~Conference}
\author{\name{\bf Ilya Gusev} \hfill  \addr{ilya.gusev@phystech.edu}\\
        \addr{MIPT, Dolgoprudny, Moscow Region, 141701, Russian Federation}
\AND
        \name{\bf Artem Oboturov} \hfill \addr{oboturov@gmail.com}
}

\maketitle
\pagestyle{empty}

\begin{abstract}
  A comparision of supervised and unsupervised NMT models was done for the corpora provided by the DeepHack.Babel competition.
  It is shown that for even small parallel corpus, fully supervised NMT gives better results than fully unsupervised for the case of constrained domain of the corpus.
  \todo[inline]{Write an abstract}
\end{abstract}

\section{Introduction}

We present results obtained by the NL Processing team during the DeepHack.Babel hackathon~\footnote{\url{http://babel.tilda.ws/}} on semi-supervised machine translation.
Organizers of the competition created an oblivious setup - the case when the source and target languages are not known and the machine translation system would be trained with no specific tuning to the language pair.
The scoring system would run training and then run translation with the trained model.
Participants have no insight into the process and could only observe the final score for a submission and/or the failure status.
Submissions were scored in BLEU-4~\citep{papineni2002bleu}.

For each language pair the following datasets~\footnote{\url{http://contest.deephack.me/c/babel/overview}} were available:
\begin{itemize}
  \item two monogingual corpora in for each language of the pair;
  \item a small parallel corpus;
  \item and an input corpus to be translated from source to target language.
\end{itemize}

One could see that the machine translation system could be built as a fully supervised one, albeit given a small parallel corpus only; as an unsupervised one, using the two monolingual corpora; and as a semi-supervised one.
Our solutions followed the fully supervised and fully unsupervised approaches only.

Given the problem at hand one could devise a number of baseline approaches and then compare them to the unsupervised model described above.
Section~\ref{sect:baselines} outlines the baselines which were used to benchmark the unsupervised NMT in the oblivious setup.
In Section~\ref{sect:unmt} we perform experiments with the unsupervised NMT model for the oblivious setup.
Finally, in Section~\ref{sect:nonoblivious} we are investigating whether prior knowledge of a language pair gives an advantage for the unsupervised NMT approach.

\section{Baselines}
\label{sect:baselines}

A supervised NMT model was chosen for the baseline.
The model was implemented in OpenNMT~\citep{opennmt} and had the following Encoder-Decoder architecture:
\begin{itemize}
\item encoder is a continuous embedding from the source language to a $300$ dimensional space;
\item followed by a $3$-layers LSTM with a dropout;
\item the decoder has a stacked LSTM with a dropout, a global attention \citep{luong2015effective} and a continuous embedding from a $300$ dimensional space,
\end{itemize}
full description is given in an Appendix~\ref{appendix:supervised}.

All those models were trained only on a {\tt 50K} parallel corpus with a {\tt 5\%} validation set.
Training time on a NVIDIA Titan XP GPU was usually measured in tens of minutes.
The results are provided in the Table~\ref{table:baselines}.
Another baseline which is reported here is a input to output copy which is reported as the {\tt no-Epochs} baseline.
Embeddings were trained with Fasttext~\citep{bojanowski2016enriching}.

\begin{table}
\begin{center}
\begin{tabular}{ l c c c }
Pair & Epochs & Oblivious Score & Conscious Score \\
\hline
\multirow{5}{4em}{En-Ru} & - & 0.02123 & - \\
& 1 & 0.10783 & \\
& 5 & 0.25747 & \\
& 10 & 0.28915 & \\
& Best & -  & 0.298 \\
\hline
\multirow{5}{4em}{Lv-En} & - & 0.02075 & - \\
& 1 & 0.01142 & \\
& 5 & 0.04766 & \\
& 10 & 0.05756 & \\
& Best & - & 0.229 \\
\hline
\multirow{5}{4em}{En-Ko} & - & 0.02759 & - \\
& 1 & 0.11179 & \\
& 5 & 0.22945 & \\
& 10 & 0.25418 & \\
& Best & - & 0.2795
\end{tabular}
\end{center}
\caption{Supervised NMT baselines, measured in BLEU scores.}
\caption*{\small
The best {\tt Lv-En} and  {\tt En-Ru} are reported on newstest2017 corpora in \cite{bojar2017findings}.
% Lv-En \url{http://matrix.statmt.org/matrix/output/1872?score_id=22981}
%\url{http://matrix.statmt.org/matrix/output/1875?score_id=21229}
{\tt En-Ko} is reported after \cite{junczys2016coppa} which uses COPPA corpus.
}
\label{table:baselines}
\end{table}

One could notice, that on the {\tt Lv-En} langauge pair, model performance was mediocre.
It could be explained by the fact that {\tt En-Ru} and {\tt En-Ko} were topic-resticted corpora - both were descriptions of hotels only, while the {\tt Lv-En} corpora was extracted from a news feed which had no topics constraints.

\section{Unsupervised Neural Machine Translation}
\label{sect:unmt}

Competition included not only parallel corpus for each language pair but  {\tt 1M} monolingual corpus for each language.
One way to leverage this data is to use unsupervised NMT model described in \cite{DBLP:journals/corr/abs-1711-00043}.
The code for this model is not available, so we built our own implementation~\footnote{\url{https://github.com/IlyaGusev/UNMT}} based on PyTorch framework. 

Our system can be used in several ways.
First, one can use it like an ordinary supervised NMT system.
Second, it can work as denoising autoencoder.
Finally, one can train this model on monolingual corpora using predefined zero model.

There are several types of zero models:
\begin{itemize}
\item word by word model;
\item supervised model trained on a small corpora;
\item unsupervised model from the previous step,
\end{itemize}
in any case, given a zero model, UNMT would train iteratively using adversarial training~\citep{goodfellow2016nips} with a discriminator described in Appendix~\ref{appendix:discriminator}.

System showed good results in first two tasks, but failed in the last one.
We don't know whether there is an error in our system or the corpora are too small.
BLEU scores on all language pairs were below {\tt 0.01 BLEU}.
The NMT model used for translation is described in Appendix~\ref{appendix:unsupervised}.

\section{Prior Language Pair Information}
\label{sect:nonoblivious}

Competition was structured in a way to prevent participants from knowing what language pairs were being tested.
The only information available to participants was the BLEU score and the failure or success status for the submission.
One could devise at least two attacks to identify the language pair and then using this prior knowledge to consturct a better translation algorithm.

First we explore the nature of those attacks and then measure what might be an impact of such knowledge.

\subsection{Side-Channel Attacks against the Language Pair}
\label{sect:attack}

We describe two ways how language pair identification attack could be executed.

\subsubsection{Using Execution Time}

There's a way to identify the language pair in one submission by using the side-channel attack technique.
In this particular case, the side-channel would be the execution time of the translation algorithm.
Whereby a language identification routine is ran on each of the non-parallel corpora and both languages of the pair are detected.
Given that the routine could identify $N$ languages, all the pairs could be enumerated to define a mapping to natural numbers in rage $1\dots N*(N-1)$.
Provided that a specific constant delay is used, one could divide the total execution time by the delay duration to obtain the index of pair in the mapping.

\subsubsection{Using Failure Status}

The second way is a slower combinatorial way where a failure status is used as an indicator of the language belonging to a subset of languages being tested.
A set of all languages identifiable by the routine could be searched in log-time in a breadth search fashion descending only into subsets where we have established inclusion relationship.

\subsection{Would Prior Knowledge Matter?}
\label{sect:prior}

In the Table~\ref{table:baselines} we also report best BLEU scores available in conference submissions for each of the pairs trained on common corpora.

We could see that a margin of improvement is just a couple of BLEU points for {\tt En-Ru} and {\tt En-Ko} pairs.
One the other hand, {\tt Lv-En} has very poor result and we would expect that both unsupervised learning and prior knowledge would improve this score.
It would make sense to only investigate the {\tt Lv-En} further.

\todo[inline]{Elaborate on Lv-En language pair}

\section{Conclusion}

\todo[inline]{Write a conclusion}

\section{Data availability and reproducibility}
Data for training and test are not available publicly, although one could ask organizers to obtain them.

Images used to train models are publicly available at \url{https://github.com/aoboturov/loresmt-nlprocessing}.

\small

\bibliographystyle{apalike}
\bibliography{mtsummit2015}

\begin{appendices}
\section{Supervised NMT Model}
\label{appendix:supervised}
\lstinputlisting{supervised-model.txt}

\section{Unsupervised NMT Model}
\label{appendix:unsupervised}
\lstinputlisting{unsupervised-model.txt}

\section{Discriminator for the Adversarial training of the UNMT Model}
\label{appendix:discriminator}
\lstinputlisting{discriminator-model.txt}

\end{appendices}

\end{document}

