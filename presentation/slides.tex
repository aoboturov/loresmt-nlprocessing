\documentclass{beamer}

\mode<presentation> {

\usetheme{Madrid}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables

\graphicspath{ {images/} }

%----------------------------------------------------------------------------------------
%   TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Supervised and Unsupervised NMT]{System description of Supervised and Unsupervised Neural Machine Translation approaches from “NL Processing” team at DeepHack.Babel task}

\author[Gusev, Oboturov]{Ilya Gusev \inst{1} \and \it{Artem Oboturov} \inst{2}}
\institute[]{\inst{1} MIPT \url{ilya.gusev@phystech.edu} \and %
                      \inst{2} \url{oboturov@gmail.com}}
\date{21 March, 2018}

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Overview}
\tableofcontents
\end{frame}

%----------------------------------------------------------------------------------------
%   PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------
\section{Competition Set-up}
%------------------------------------------------

\begin{frame}
\frametitle{Competition Set-up}

\begin{itemize}
\item the blind set-up: source and target languages are not known
\item teams provide model blueprints to organizers
\item organizers perform both training and inference on hidden data
\item resources for training and inference are intentionally constrained
\item total number of submissions is limited
\end{itemize}

\onslide<2-4>{
\begin{block}{Incentives}
\begin{itemize}
\item<2-4> one could not just use hyper-parameter optimization to get better scores
\item<3-4> ensembling is still possible
\item<4> the set-up encourages to provide a universal blueprint
\end{itemize}
\end{block}
}

\end{frame}

%------------------------------------------------
\section{Baseline}
%------------------------------------------------

\begin{frame}
\frametitle{Fully Supervised NMT Model}

\begin{itemize}
\item fast to train (20-30 mins on GPU)
\item available off-the-shelf in OpenNMT
\item permits to establish a very strait forward baseline
\item<2-3> the encoder is $3$ LSTM layers with a dropout based on $300$ dimensional word embeddings for the source language,
\item<2-3> the decoder is stacked LSTM layers with a dropout and a global attention based on $300$ dimensional word embeddings for the target language.
\end{itemize}

\onslide<3>{
\begin{table}
\begin{tabular}{c c c}
\toprule
En-Ru Score & Lv-En Score & En-Ko Score\\
\midrule
0.2892 & 0.0576 & 0.2542 \\
\bottomrule
\end{tabular}
\caption{Supervised, 10 epochs, measured in BLEU-4}
\end{table}
}

\end{frame}

%------------------------------------------------
\section{Unsupervised Neural Machine Translation}
%------------------------------------------------

\begin{frame}
\frametitle{Semi \& Unsupervised NMT Model with Adversarial Training: the Set-up}

\begin{columns}
\column{0.47\linewidth}
\centering
\begin{figure}
\includegraphics[width=5cm]{unmt.png}
\caption{Adversarial training process}
\end{figure}
\column{0.47\linewidth}
\begin{itemize}
\item implementation of the ``Unsupervised Machine Translation Using Monolingual Corpora Only'' adversarial training
\item in this case NMT model = encoder + decoder
\end{itemize}
\end{columns}

\end{frame}

\begin{frame}
\frametitle{Semi \& Unsupervised NMT Model with Adversarial Training: the Training Process}

\begin{columns}
\column{0.47\linewidth}
\begin{itemize}
\item train the initial model somehow:
\begin{itemize}
\item supervised model - would be semi-supervised learning
\item unsupervised model - would be fully unsupervised model
\end{itemize}
\item iterate over trained models starting from the initial model by minimizing adversarial loss, defined as sum of binary cross entropies of discriminator outputs vs expected language, plus NLLs from denoising autoencoder and translation with noise encoder
\end{itemize}
\centering
\column{0.47\linewidth}
\begin{figure}
\includegraphics[width=5cm]{discriminator.png}
\caption{Discriminator architecture}
\end{figure}
\end{columns}

\end{frame}

\begin{frame}
\frametitle{Semisupervised NMT Model with Adversarial Training: Architecture of Encoder and Decoder}

\begin{columns}
\column{0.47\linewidth}
\centering
\begin{figure}
\includegraphics[width=5cm]{encoder.png}
\caption{Encoder architecture}
\end{figure}
\column{0.47\linewidth}
\begin{figure}
\includegraphics[width=4.5cm]{decoder.png}
\caption{Decoder architecture}
\end{figure}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Semisupervised NMT Model with Adversarial Training: Initial Models}

\begin{itemize}
\item dictionary translation
\begin{itemize}
\item word by word with unknowns
\item word by word with alignment
\end{itemize}
\item fully supervised trained on a 50k parallel corpus
\end{itemize}

\end{frame}

%------------------------------------------------
\section{Hands on}
%------------------------------------------------

\begin{frame}
\frametitle{Implementations}

\begin{itemize}
\item our implementation for the hackathon \url{https://github.com/IlyaGusev/UNMT}
\begin{table}
\begin{tabular}{l c c c}
\toprule
Set-up & En-Ru Score & Lv-En Score & En-Ko Score\\
\midrule
Unsupervised UNMT & - & 0.0043 & - \\
Semi-supervised UNMT & - & - & 0.0018 \\
\bottomrule
\end{tabular}
\caption{UNMT results, measured in BLEU-4}
\end{table}
\item<2-3> the one produced by the OpenNMT team \url{https://github.com/OpenNMT/Hackathon/tree/master/unsupervised-nmt} - yet to be tested
\item<3> our project \url{https://github.com/aoboturov/loresmt-nlprocessing}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{How our work could be useful for you?}

\begin{itemize}
\item Lampe's model is universal in the sense that one could provide data and it should work regardless of the language pair
\item one could boostrap on any other dataset using our or OpenNMT implementations
\item baseline model and UNMT are provided as docker images which one could built locally and test if such an approach works for other datasets.
\end{itemize}

\end{frame}

%------------------------------------------------
\section{Blind set-up}
%------------------------------------------------

\begin{frame}
\frametitle{Blind Set-up Vulnurabilities}

\begin{itemize}
\item one could identify the language pairs with a side-channel attack
\item execution time attack
\item tree search attack
\end{itemize}

\end{frame}

%------------------------------------------------
\section{Bibliography}
%------------------------------------------------

\begin{frame}[allowframebreaks]
\frametitle<presentation>{Further Reading}
\begin{thebibliography}{10}
\beamertemplatebookbibitems
\setbeamertemplate{bibliography item}[text]
\bibitem{Lampe2018}
{Guillaume Lample and Ludovic Denoyer and Marc'Aurelio Ranzato}
\newblock Unsupervised Machine Translation Using Monolingual Corpora Only.
\newblock \url{http://arxiv.org/abs/1711.00043}.
\end{thebibliography}
\end{frame}

%----------------------------------------------------------------------------------------

\end{document}
